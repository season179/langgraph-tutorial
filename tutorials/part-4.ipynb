{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Human-in-the-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # This is new!\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # Note: can also interrupt __after__ actions, if desired.\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_015gknwt2qxENRPRFhF7Fh5G', 'input': {'query': 'LangGraph Python library for language models'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_015gknwt2qxENRPRFhF7Fh5G)\n",
      " Call ID: toolu_015gknwt2qxENRPRFhF7Fh5G\n",
      "  Args:\n",
      "    query: LangGraph Python library for language models\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph Python library for language models'},\n",
       "  'id': 'toolu_015gknwt2qxENRPRFhF7Fh5G'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://pypi.org/project/langgraph/\", \"content\": \"Project details\\nProject links\\nStatistics\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery\\nMeta\\nLicense: Other/Proprietary License (LangGraph License)\\nRequires: Python >=3.9.0, <4.0\\nMaintainers\\nClassifiers\\nRelease history\\nRelease notifications |\\nRSS feed\\n0.0.24\\nFeb 8, 2024\\n0.0.23\\nFeb 4, 2024\\n0.0.22\\nFeb 4, 2024\\n0.0.21\\nJan 31, 2024\\n0.0.20\\nJan 27, 2024\\n0.0.19\\nJan 23, 2024\\n0.0.18\\nJan 23, 2024\\n0.0.17\\nJan 23, 2024\\n0.0.16\\nJan 21, 2024\\n0.0.15\\nJan 19, 2024\\n0.0.14\\nJan 18, 2024\\n0.0.13\\nJan 17, 2024\\n0.0.12\\nJan 17, 2024\\n0.0.11\\nJan 16, 2024\\n0.0.10\\nJan 9, 2024\\n0.0.9\\nJan 8, 2024\\n0.0.8\\nyanked\\nJan 8, 2024\\nDownload files\\nDownload the file for your platform. langgraph 0.0.24\\npip install langgraph\\nCopy PIP instructions\\nReleased:\\nFeb 8, 2024\\nlanggraph\\nNavigation\\nProject links\\nStatistics\\nView statistics for this project via Libraries.io, or by using our public dataset on Google BigQuery\\nMeta\\nLicense: Other/Proprietary License (LangGraph License)\\nRequires: Python >=3.9.0, <4.0\\nMaintainers\\nClassifiers\\nProject description\\n\\ud83e\\udd9c\\ud83d\\udd78\\ufe0fLangGraph\\n\\u26a1 Building language agents as graphs \\u26a1\\nOverview\\nLangGraph is a library for building stateful, multi-actor applications with LLMs, built on top of (and intended to be used with) LangChain.\\n Source Distribution\\nUploaded\\nFeb 8, 2024\\nsource\\nBuilt Distribution\\nUploaded\\nFeb 8, 2024\\npy3\\nHashes for langgraph-0.0.24.tar.gz\\nHashes for langgraph-0.0.24-py3-none-any.whl\\nHelp\\nAbout PyPI\\n It only has one argument:\\nNote: This does not need to be called if at any point you previously created an edge (conditional or normal) to END\\nGraph\\nThis has the same interface as StateGraph with the exception that it doesn't update a state object over time, and rather relies on passing around the full state from each step.\\n If the agent said that it was finished, then it should finish\\nNormal Edge: after the tools are invoked, it should always go back to the agent to decide what to do next\\nLet's define the nodes, as well as a function to decide how what conditional edge to take.\\n\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your patience. I've researched LangGraph for you, and I'm happy to share what I've found. LangGraph is a relatively new and exciting library in the field of language models and AI. Here's an overview of LangGraph based on the latest information:\n",
      "\n",
      "1. Description:\n",
      "LangGraph is a Python library for building stateful, multi-actor applications with Large Language Models (LLMs). It's designed to be used in conjunction with LangChain, another popular library in the LLM ecosystem.\n",
      "\n",
      "2. Key Features:\n",
      "   - Allows building language agents as graphs\n",
      "   - Supports stateful applications\n",
      "   - Enables multi-actor systems\n",
      "   - Offers cycles, controllability, and persistence\n",
      "\n",
      "3. Main Benefits:\n",
      "   - Cycles: LangGraph allows you to define flows that involve cycles, which is essential for most agent architectures.\n",
      "   - Controllability: It provides more control over the flow of your LLM-based applications.\n",
      "   - Persistence: The library supports maintaining state across interactions.\n",
      "\n",
      "4. Use Cases:\n",
      "   - Creating agent and multi-agent workflows\n",
      "   - Building complex, stateful LLM applications\n",
      "\n",
      "5. Technical Details:\n",
      "   - Requires Python version 3.9 or higher, but less than 4.0\n",
      "   - Latest version: 0.0.24 (as of February 8, 2024)\n",
      "   - Licensed under the LangGraph License (Other/Proprietary)\n",
      "\n",
      "6. Core Concepts:\n",
      "   - StateGraph: A main component that allows updating a state object over time\n",
      "   - Graph: Similar to StateGraph but relies on passing around the full state from each step\n",
      "   - Nodes and Edges: Used to define the structure and flow of your application\n",
      "   - Conditional Edges: Allow for dynamic routing based on the current state\n",
      "\n",
      "7. Installation:\n",
      "   You can install LangGraph using pip:\n",
      "   ```\n",
      "   pip install langgraph\n",
      "   ```\n",
      "\n",
      "8. Development:\n",
      "   LangGraph is actively developed, with frequent updates. The release history shows regular improvements and updates.\n",
      "\n",
      "9. Community and Support:\n",
      "   As part of the LangChain ecosystem, it likely benefits from the broader community support and resources available for LangChain users.\n",
      "\n",
      "LangGraph seems to be a powerful tool for developers looking to create more complex and stateful applications using LLMs, especially when working with agent-based systems. It's particularly useful if you're already familiar with LangChain and want to extend your capabilities in building more sophisticated AI applications.\n",
      "\n",
      "Is there any specific aspect of LangGraph you'd like to know more about? I'd be happy to dive deeper into any particular feature or concept.\n"
     ]
    }
   ],
   "source": [
    "# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
